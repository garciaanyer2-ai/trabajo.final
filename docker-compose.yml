services:
  # ---------------------------------------------------------------------------
  # Database Service: PostgreSQL
  # ---------------------------------------------------------------------------
  postgres:
    image: postgres:15-alpine
    container_name: tf_postgres
    environment:
      POSTGRES_USER: ${DB_USER:-postgres}
      POSTGRES_PASSWORD: ${DB_PASSWORD:-postgres}
      POSTGRES_DB: ${DB_NAME:-trabajo_final}
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      # Mount the sql file to initialize the database automatically if needed
      - ./sql/import_data.sql:/docker-entrypoint-initdb.d/init.sql
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U postgres" ]
      interval: 5s
      timeout: 5s
      retries: 5
    networks:
      - tf_network

  # ---------------------------------------------------------------------------
  # Spark Master
  # ---------------------------------------------------------------------------
  spark-master:
    image: apache/spark:3.5.4-python3
    container_name: tf_spark_master
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    ports:
      - '8080:8080' # Spark Master UI
      - '7077:7077' # Spark Master Port
    volumes:
      - .:/opt/spark/trabajo_final
    networks:
      - tf_network
    command: [ "/opt/spark/bin/spark-class", "org.apache.spark.deploy.master.Master", "--ip", "spark-master", "--port", "7077", "--webui-port", "8080" ]
    # Removed entrypoint to use default shell execution if needed or let command handle it

    # ---------------------------------------------------------------------------
    # Spark Worker
    # ---------------------------------------------------------------------------
  spark-worker:
    image: apache/spark:3.5.4-python3
    container_name: tf_spark_worker
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    depends_on:
      - spark-master
    volumes:
      - .:/opt/spark/trabajo_final
    networks:
      - tf_network
    command: [ "/opt/spark/bin/spark-class", "org.apache.spark.deploy.worker.Worker", "spark://spark-master:7077" ]
    # Removed entrypoint to use default shell execution if needed

volumes:
  postgres_data:


networks:
  tf_network:
    driver: bridge
