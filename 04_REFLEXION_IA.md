# Paso 4: Reflexion IA - Proceso de Aprendizaje

**Alumno:** Anyerlin Ravelo

> **Instrucciones:** Para cada bloque (A, B, C), responde 3 preguntas y pega
> el prompt MAS IMPORTANTE que usaste en ese bloque.
>
> Se valoran respuestas **ESPECIFICAS** y **HONESTAS**. No importa si usaste
> IA o no. Lo que importa es que demuestres tu proceso de aprendizaje real.
>
> **Lo que evaluamos:** Tus prompts y tu capacidad de explicar que hiciste.
> Un codigo perfecto con reflexion vacia = nota baja.

---

## Bloque A: Infraestructura Docker

### Momento 1 - Arranque
**Que fue lo primero que le pediste a la IA o buscaste en internet?**

Lo primero que busqu칠 fue c칩mo configurar el entorno inicial cuando me di cuenta de que no ten칤a Docker ni Python instalado en mi m치quina local. Le pregunt칠 a la IA: "Tengo que preparar un proyecto de an치lisis de datos con el dataset de QoG, pero no tengo instalado Docker ni Git en mi Windows, 쯖칩mo puedo descargar los datos y procesarlos manualmente usando solo PowerShell y SQL?".

### Momento 2 - Error
**Que fallo y como lo resolviste? (pega el error si lo tienes)**

El principal fallo fue tratar de trabajar con el archivo `qog_std_ts_jan24.csv` directamente en un editor de texto o Excel para limpiarlo, pero pesaba m치s de 100MB y se colgaba todo. Intent칠 hacer un script b치sico pero me daba error de memoria. La IA me ayud칩 a entender que deb칤a procesar el archivo por "chunks" o l칤neas. El script de PowerShell `prep_data.ps1` fue la soluci칩n para filtrar las 15,000 filas sin saturar la RAM.

### Momento 3 - Aprendizaje
**Que aprendiste que NO sabias antes de empezar este bloque?**

Aprend칤 que en entornos restringidos (donde no puedes instalar Docker o Python f치cilmente), PowerShell es una herramienta extremadamente potente para la manipulaci칩n de archivos CSV grandes mediante objetos de tipo `StreamReader`. Tambi칠n aprend칤 la importancia de definir el esquema de la base de datos (DDL) antes de intentar importar datos masivos con comandos como `COPY`.

### Prompt clave del Bloque A

**Herramienta:** Claude / ChatGPT

| Nivel | Prompt Utilizado / Propuesto |
|:---|:---|
| **游릭 Principiante** | "Tengo un archivo CSV gigante que no abre y quiero sacar unas columnas de pa칤ses con terrorismo sin que se rompa mi PC." |
| **游댯 Actual** | "Necesito un script de PowerShell que lea el archivo qog_std_ts_jan24.csv l칤nea por l칤nea, extraiga solo las columnas ucdp_type1, ucdp_type2, ucdp_type3, ucdp_type4, wdi_gdpcapcur, wdi_pop, ccode, cname y year, y guarde el resultado en un nuevo CSV." |
| **游댮 Experto** | "Genera un script de PowerShell optimizado que use `System.IO.StreamReader` para procesar un CSV de 120MB. Implementa un pipeline que filtre por $ccodealp y seleccione columnas espec칤ficas mediante un objeto PSObject personalizado, exportando a CSV con codificaci칩n UTF8 para evitar p칠rdida de caracteres en nombres de pa칤ses." |

**Por que fue clave:** La evoluci칩n hacia el prompt experto demuestra que entiendo c칩mo gestionar los recursos del sistema (RAM y CPU) mediante el procesamiento de flujos de datos en lugar de la carga masiva en memoria.

---

## Bloque B: Pipeline ETL

### Momento 1 - Arranque
**Que fue lo primero que le pediste a la IA o buscaste en internet?**

Al empezar el Bloque B, ya con el entorno un poco m치s estable, le ped칤 ayuda para estructurar el script de Spark: "Necesito crear un pipeline de Spark en Python (pyspark) que filtre el dataset de QoG para Espa침a, Francia, Turqu칤a, Afganist치n y Rusia entre los a침os 2000 y 2023, y que adem치s calcule una columna nueva del gasto militar por persona".

### Momento 2 - Error
**Que fallo y como lo resolviste?**

Tuve un error con los tipos de datos al calcular la variable derivada `mil_exp_capita`. El error era: `PySparkTypeError: [CANNOT_APPLY_DIFF_TYPES] Cannot apply operator '*' on different types: double and string`. Resulta que algunas columnas se estaban leyendo como texto por los valores "NA". Lo resolv칤 usando `cast("double")` y gestionando los nulos con `coalesce` dentro del pipeline.

### Momento 3 - Aprendizaje
**Que aprendiste que NO sabias antes de empezar este bloque?**

Aprend칤 la diferencia pr치ctica entre guardar datos en CSV y en Parquet. No sab칤a que Parquet guardaba el esquema y los tipos de datos, lo que evita tener que definir los tipos de nuevo al leer el archivo para el an치lisis. Tambi칠n entend칤 mejor el concepto de "Lazy Evaluation" en Spark: nada se ejecuta hasta que llam칠 a `.write`.

### Prompt clave del Bloque B

**Herramienta:** ChatGPT / Github Copilot

| Nivel | Prompt Utilizado / Propuesto |
|:---|:---|
| **游릭 Principiante** | "Hazme un c칩digo de Spark para filtrar el CSV del QoG por a침os y pa칤ses y gu치rdalo en Parquet." |
| **游댯 Actual** | "Crea un script pipeline.py que use PySpark para: 1. Leer qog_std_ts_jan24.csv. 2. Filtrar ccodealp para ['ESP', 'FRA', 'TUR', 'AFG', 'RUS'] y a침os entre 2000 y 2023. 3. Crear mil_exp_capita. 4. Guardar en Parquet." |
| **游댮 Experto** | "Escribe un Pipeline ETL en PySpark que implemente `inferSchema=False` con un StructType definido para optimizar el JOB. Realiza una limpieza de valores nulos en el campo militar mediante `coalesce` y genera una variable derivada tipada como DoubleType. Configura el nivel de particionamiento a 5 antes de escribir en Parquet." |

**Por que fue clave:** Pasar de un prompt gen칠rico a uno con especificaciones t칠cnicas de paralelismo y tipado de datos permite que Spark funcione mucho m치s r치pido y sin errores de ejecuci칩n.

---

## Bloque C: Analisis y Visualizacion

### Momento 1 - Arranque
**Que fue lo primero que le pediste a la IA o buscaste en internet?**

Busqu칠 c칩mo hacer gr치ficos comparativos de series temporales para varios pa칤ses a la vez: "C칩mo usar matplotlib para graficar la evoluci칩n de dos indicadores diferentes (gasto militar e 칤ndice de democracia) para 5 pa칤ses en gr치ficos separados pero consistentes".

### Momento 2 - Error
**Que fallo y como lo resolviste?**

Al intentar graficar los datos de Afganist치n, el gr치fico se ve칤a "roto" porque hab칤a muchos a침os sin datos (huecos en la l칤nea). La IA me sugiri칩 usar `marker='o'` para que los puntos individuales fueran visibles incluso si no hab칤a una l칤nea continua, y a ordenar el DataFrame por a침o antes de graficar para que las l칤neas no se cruzaran de forma err치tica.

### Momento 3 - Aprendizaje
**Que aprendiste que NO sabias antes de empezar este bloque?**

Aprend칤 a interpretar datos sociales y pol칤ticos compar치ndolos. Fue revelador ver gr치ficamente c칩mo en pa칤ses como Turqu칤a o Rusia, el 칤ndice `vdem_libdem` (democracia liberal) cae en picado justo cuando el gasto militar se mantiene alto o sube. Entend칤 que la visualizaci칩n de datos no es solo hacer dibujos bonitos, sino encontrar historias de correlaci칩n.

### Prompt clave del Bloque C

**Herramienta:** Claude

| Nivel | Prompt Utilizado / Propuesto |
|:---|:---|
| **游릭 Principiante** | "Quiero hacer un dibujo con l칤neas de colores para mostrar los gr치ficos del gasto militar." |
| **游댯 Actual** | "Ay칰dame a escribir un script con matplotlib que genere dos gr치ficos: uno con el gasto militar y otro con la democracia liberal, usando un bucle para que cada pa칤s tenga su propia l칤nea y leyenda." |
| **游댮 Experto** | "Desarrolla una funci칩n modular en Matplotlib que reciba un DataFrame y genere una grilla de subplots comparativos. Usa un diccionario de colores est치tico por 'ccodealp', implementa un suavizado opcional de l칤neas (rolling mean) y asegura que el eje X est칠 sincronizado entre ambos gr치ficos para facilitar la comparaci칩n temporal." |

**Por que fue clave:** La modularidad solicitada en el nivel experto permite que el an치lisis sea reproducible y est칠ticamente profesional, facilitando la detecci칩n de patrones visuales complejos.
